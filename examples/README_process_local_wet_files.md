# Processing Local WET.gz Files

This document provides instructions on how to use the `process_local_wet_files.py` script to process Common Crawl WET files locally using a `datatrove` pipeline with Ray.

## Dependencies

### Main Dependencies
The script relies on `datatrove` and `ray`.

*   **Ray**: If you haven't installed `ray` with the necessary extras, you can install it via pip. A common set of extras is:
    ```bash
    pip install "ray[data,train,tune]"
    ```
    A more minimal installation like `pip install ray` might be sufficient, but `ray[data]` is often recommended for data processing workloads. Please refer to the official Ray documentation for the most suitable installation for your setup.

*   **Datatrove**: Ensure `datatrove` is installed. If you installed it from source or via pip, it should handle its core dependencies.

### WarcReader Dependencies
The `WarcReader` used in the script has specific dependencies:
*   `warcio`: For reading WARC/WET files.
*   `cchardet`: For fast character encoding detection.
*   `python-magic`: For identifying file types (used by some underlying components).

These are typically installed as dependencies of `datatrove`. However, it's good to be aware of them, especially if you encounter any issues related to file reading or encoding.

## Configuration

Before running the script, you need to configure the pipeline by editing the global variables at the top of the `examples/process_local_wet_files.py` file.

Key configuration variables:

*   `INPUT_DIR`: Set this to the path of your local directory containing the WET files.
    *   Example: `INPUT_DIR = "/path/to/your/wet/files/"`
*   `OUTPUT_DIR`: Set this to the path where the processed JSONL files and excluded files will be saved.
    *   Example: `OUTPUT_DIR = "/path/to/your/output/"`
*   `LANGUAGES`: A list of language codes (e.g., "en", "es", "fr") to filter by. Documents matching any of these languages will be kept.
    *   Example: `LANGUAGES = ["en"]` or `LANGUAGES = ["en", "es"]`
*   `GLOB_PATTERN`: The glob pattern used to find WET files within the `INPUT_DIR`.
    *   Default: `GLOB_PATTERN = "*.wet.gz"`
*   `RAY_TASKS`: The number of parallel Ray tasks to use for processing. Adjust this based on your machine's capacity (e.g., number of CPU cores).
    *   Default: `RAY_TASKS = 2`
*   `LOGGING_DIR`: The directory where pipeline logs (specifically Ray logs) will be stored.
    *   Default: `LOGGING_DIR = "pipeline_logs/"`

Example configuration block in the script:

```python
# Configuration variables
INPUT_DIR = "data/wet_files/"  # TODO: Update this path
OUTPUT_DIR = "output/processed_data/"  # TODO: Update this path
LANGUAGES = ["en", "es"]  # TODO: Update with desired languages
GLOB_PATTERN = "*.wet.gz"
RAY_TASKS = 2
LOGGING_DIR = "pipeline_logs/"
```
**Important:** Make sure to update `INPUT_DIR`, `OUTPUT_DIR`, and `LANGUAGES` according to your specific file locations and processing needs.

## Running the Script

Once you have configured the variables in `examples/process_local_wet_files.py`, you can run the script directly from the root of the `datatrove` repository:

```bash
python examples/process_local_wet_files.py
```

## Output Structure

The script will generate output in the directories specified by the `OUTPUT_DIR` and `LOGGING_DIR` configuration variables:

*   **Filtered Output**:
    *   Location: `OUTPUT_DIR/filtered_<lang1>_<lang2>.../`
    *   Content: JSONL files containing documents that matched the language(s) specified in the `LANGUAGES` variable. For example, if `LANGUAGES = ["en", "es"]`, the folder will be `filtered_en_es`.

*   **Excluded Output (from Language Filter)**:
    *   Location: `OUTPUT_DIR/non_<lang1>_<lang2>.../`
    *   Content: JSONL files containing documents that did *not* match the specified language(s) and were thus excluded by the `LanguageFilter`. The language codes in the path correspond to those in the `LANGUAGES` variable.

*   **Logs**:
    *   Location: `LOGGING_DIR/ray_logs/`
    *   Content: Log files generated by the Ray executor during the pipeline run. These are useful for debugging and monitoring progress.

Make sure the output directories and logging directory (as defined in the script's configuration variables) are writable. If they don't exist, the script (or Ray) will attempt to create them.
